{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#from pycountry_convert import ( map_countries, country_name_to_country_alpha3,)\n",
    "import pytz as pytz\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#lgm and graph viz\n",
    "import graphviz \n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9fceeef9e657c72a7dd152f0a084829d7a642b8"
   },
   "outputs": [],
   "source": [
    "def load_df(csv_path='../input/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "      \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str', 'visitId':'str', 'visitStartTime':'str', 'date':'str'}, \n",
    "                     nrows=nrows)\n",
    "\n",
    "    #Normalize JSON colunmns and drop\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_constant_cols(df):\n",
    "    ## Drop constant columns\n",
    "    const_cols = [c for c in df.columns if df[c].nunique(dropna=False) == 1]\n",
    "    df.drop(const_cols, axis=1, inplace=True)\n",
    "    \n",
    "    #this columnm is only in train data\n",
    "    try:\n",
    "        df.drop('trafficSource.campaignCode', axis=1, inplace=True)   \n",
    "    except:\n",
    "        None   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13e5a6bf02268a370e6493ac28e52a349ebe0c69"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "014943e71faed7e9fe2ee1b3b6a9d3578c0b912f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Load\n",
    "train_df = load_df(csv_path='../input/ga-customer-revenue-prediction/train.csv', nrows = None)\n",
    "#train_df.to_pickle('train_flat_no_drop.pkl')\n",
    "drop_constant_cols(train_df)\n",
    "\n",
    "test_df = load_df(csv_path='../input/ga-customer-revenue-prediction/test.csv', nrows = None)\n",
    "#train_df.to_pickle('test_flat_no_drop.pkl')\n",
    "drop_constant_cols(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "812505f0f2eb398ab2afa150e29ac2e1924c4e18"
   },
   "outputs": [],
   "source": [
    "# Extract target values and Ids\n",
    "cat_cols = ['channelGrouping','device.browser',\n",
    "       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\n",
    "       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n",
    "       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n",
    "       'geoNetwork.subContinent','trafficSource.adContent',\n",
    "       'trafficSource.adwordsClickInfo.adNetworkType',\n",
    "       'trafficSource.adwordsClickInfo.gclId',\n",
    "       'trafficSource.adwordsClickInfo.isVideoAd',\n",
    "       'trafficSource.adwordsClickInfo.page',\n",
    "       'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign',\n",
    "       'trafficSource.isTrueDirect', 'trafficSource.keyword',\n",
    "       'trafficSource.medium', 'trafficSource.referralPath',\n",
    "       'trafficSource.source'  ]\n",
    "\n",
    "\n",
    "num_cols = ['visitNumber', 'totals.bounces', 'totals.hits',\n",
    "            'totals.newVisits', 'totals.pageviews', \n",
    "            '_local_hourofday'  ]\n",
    "\n",
    "interaction_cols = ['totals.hits / totals.pageviews', 'totals.hits * totals.pageviews',\n",
    "       'totals.hits - totals.pageviews']\n",
    "\n",
    "visitStartTime = ['visitStartTime']\n",
    "\n",
    "ID_cols = ['date', 'fullVisitorId', 'sessionId', 'visitId']\n",
    "\n",
    "target_col = ['totals.transactionRevenue']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2897e2379eea48e2364f522c3b06cd3ae58c11fe"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input/geocodes-timezones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "546bc830b066e9e2f4d92eb020a1ced7e21cd8d7"
   },
   "outputs": [],
   "source": [
    "#Load\n",
    "geocode_df= pd.read_pickle('../input/geocodes-timezones/geocodes_timezones.pkl')\n",
    "\n",
    "def time_zone_converter(x):\n",
    "    \n",
    "    try:\n",
    "        return pytz.country_timezones(x)[0]\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "   \n",
    "\n",
    "def time_localizer(s):\n",
    "    #format of series [time,zone]\n",
    "    try:\n",
    "        tz =pytz.timezone(s[1])\n",
    "        return pytz.utc.localize(s[0], is_dst=None).astimezone(tz)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def remove_missing_vals(x):\n",
    "    remove_list = ['(not set)', 'not available in demo dataset','unknown.unknown']\n",
    "    if x in remove_list:\n",
    "        return ''\n",
    "    else:\n",
    "        return x \n",
    "    \n",
    "def map_timezone(x):   \n",
    "    try:\n",
    "        return timezone_dict[x]\n",
    "    except KeyError:\n",
    "        return 'UTC'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df['visitStartTime'] = pd.to_datetime(train_df['visitStartTime'], unit = 's')\n",
    "test_df['visitStartTime'] = pd.to_datetime(test_df['visitStartTime'], unit = 's')\n",
    "\n",
    "#Generate foreign key '_search_term' by concatenating city, region, country\n",
    "train_df['_search_term'] = train_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.country'].map(remove_missing_vals)\n",
    "test_df['_search_term'] = test_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.country'].map(remove_missing_vals)\n",
    "\n",
    "#Set global variable, needed for map_timezone function\n",
    "global timezone_dict\n",
    "timezone_dict = dict(zip(geocode_df['search_term'], geocode_df['timeZoneId']))\n",
    "\n",
    "#Map timezones\n",
    "train_df['_timeZoneId'] = train_df['_search_term'].map(map_timezone)\n",
    "test_df['_timeZoneId'] = test_df['_search_term'].map(map_timezone)\n",
    "  \n",
    "#Create time zone aware column\n",
    "train_df['_local_time'] = train_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)\n",
    "test_df['_local_time'] = test_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)  \n",
    "\n",
    "#Localize hour time\n",
    "train_df['_local_hourofday'] = train_df['_local_time'].str[11:13]\n",
    "test_df['_local_hourofday'] = test_df['_local_time'].str[11:13]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71f493e7c8bac0ee6b027da699e8788a63bca12b"
   },
   "outputs": [],
   "source": [
    "def map_longitude(x):   \n",
    "    try:\n",
    "        return longitude_dict[x]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "    \n",
    "def map_latitude(x):   \n",
    "    try:\n",
    "        return latitude_dict[x]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "    \n",
    "global longitude_dict\n",
    "longitude_dict = dict(zip(geocode_df['search_term'], geocode_df['geometry.location.lng']))\n",
    "\n",
    "global latitude_dict\n",
    "latitude_dict = dict(zip(geocode_df['search_term'], geocode_df['geometry.location.lat']))\n",
    "\n",
    "\n",
    "#Map latitude\n",
    "train_df['_latitude'] = train_df['_search_term'].map(map_latitude)\n",
    "test_df['_latitude'] = test_df['_search_term'].map(map_latitude)\n",
    "\n",
    "#Map longitude\n",
    "train_df['_longitude'] = train_df['_search_term'].map(map_longitude)\n",
    "test_df['_longitude'] = test_df['_search_term'].map(map_longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdd2458cf8656f32e2dba37f91466cc44d77711f"
   },
   "source": [
    "# Time since last visit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81decb31ba798fdb596d8ec7eb3adb2531df3d06"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_ts = train_df[['fullVisitorId', 'sessionId', 'visitId', 'visitNumber', 'visitStartTime']].copy()\n",
    "test_ts = test_df[['fullVisitorId', 'sessionId', 'visitId', 'visitNumber', 'visitStartTime']].copy()\n",
    "\n",
    "\n",
    "train_df['_time_since_last_visit'] = train_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff()\n",
    "test_df['_time_since_last_visit'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb989c825dd9d2e7d3cb1d132ccb7c43e9df98a9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#train_df['_time_since_last_visit'] = pd.to_numeric(train_df['_time_since_last_visit'])\n",
    "#test_df['_time_since_last_visit'] = pd.to_numeric(test_df['_time_since_last_visit'])\n",
    "\n",
    "#Preparation\n",
    "wip_cols = ['fullVisitorId', 'sessionId', 'visitId',\n",
    "       'visitNumber', 'visitStartTime','totals.bounces', 'totals.hits',\n",
    "       'totals.newVisits', 'totals.pageviews', '_time_since_last_visit']\n",
    "\n",
    "train_ts = train_df.sort_values(['fullVisitorId', 'visitStartTime']).reset_index()\n",
    "train_ts['index'] = train_ts['index'].astype('str')\n",
    "train_ts_grouped = train_ts.groupby('fullVisitorId')\n",
    "\n",
    "#Calculating rolling frequency\n",
    "temp_roll = train_ts_grouped.rolling('1H', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_1H') \n",
    "train_ts = pd.concat([train_ts, temp_roll['visitNumber_1H']], axis = 1)\n",
    "\n",
    "temp_roll = train_ts_grouped.rolling('1D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_1D') \n",
    "train_ts = pd.concat([train_ts, temp_roll['visitNumber_1D']], axis = 1)\n",
    "\n",
    "temp_roll = train_ts_grouped.rolling('30D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_30D') \n",
    "train_ts = pd.concat([train_ts, temp_roll['visitNumber_30D']], axis = 1)\n",
    "\n",
    "train_ts['index'] = train_ts['index'].astype('int')\n",
    "train_ts.set_index('index', inplace = True)\n",
    "train_ts.sort_index(inplace = True)\n",
    "train_df = train_ts.copy()\n",
    "del train_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b44d131fbc763feba1c71e13f14172438e731a7b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_ts = test_df.sort_values(['fullVisitorId', 'visitStartTime']).reset_index()\n",
    "test_ts['index'] = test_ts['index'].astype('str')\n",
    "test_ts_grouped = test_ts.groupby('fullVisitorId')\n",
    "\n",
    "#Calculating rolling frequency\n",
    "temp_roll = test_ts_grouped.rolling('1H', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_1H') \n",
    "test_ts = pd.concat([test_ts, temp_roll['visitNumber_1H']], axis = 1)\n",
    "\n",
    "temp_roll = test_ts_grouped.rolling('1D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_1D') \n",
    "test_ts = pd.concat([test_ts, temp_roll['visitNumber_1D']], axis = 1)\n",
    "\n",
    "temp_roll = test_ts_grouped.rolling('30D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_30D')\n",
    "test_ts = pd.concat([test_ts, temp_roll['visitNumber_30D']], axis = 1)\n",
    "\n",
    "test_ts['index'] = test_ts['index'].astype('int')\n",
    "test_ts.set_index('index', inplace = True)\n",
    "test_ts.sort_index(inplace = True)\n",
    "test_df = train_ts.copy()\n",
    "del test_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5ef3941b6c320562128fb5c4978c6962b7f0d58"
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_flat_FE.pkl')\n",
    "test_df.to_pickle('test_flat_FE.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c77bc200b9640b24bc514148854ad3b1c81fcc3b"
   },
   "source": [
    "# Categoricals processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b551a41c89a17721a4c1a99e152270ffc5c83a38"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Categorical encoding\n",
    "for c in cat_cols:\n",
    "    #Convert NAs to unknown\n",
    "    train_df[c] = train_df[c].fillna('unknown')\n",
    "    test_df[c] = test_df[c].fillna('unknown')\n",
    "\n",
    "\n",
    "#Rename \"Other\" those with less than 10\n",
    "for col in cat_cols:\n",
    "    #For train data\n",
    "    series1 = pd.value_counts(train_df[col])\n",
    "    mask1 = series1 < 10\n",
    "    train_df[col] = np.where(train_df[col].isin(series1[mask1].index),'Other_{}'.format(col), train_df[col])\n",
    "    \n",
    "    #For test data\n",
    "    series2 = pd.value_counts(test_df[col])\n",
    "    mask2 = series2 < 10\n",
    "    test_df[col] = np.where(test_df[col].isin(series2[mask2].index),'Other_{}'.format(col), test_df[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45fa96ce3e0ddf81f7a19302126b705f045a16fe"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "interact_cats = ['channelGrouping', 'device.operatingSystem',\n",
    "                'geoNetwork.city', 'geoNetwork.country', 'geoNetwork.networkDomain',\n",
    "                 'trafficSource.medium', \n",
    "                'trafficSource.referralPath', 'trafficSource.source']\n",
    "\n",
    "#2-way interactions\n",
    "from itertools import combinations\n",
    "\n",
    "def categorical_interaction_terms_2(df, columns):\n",
    "    for c in combinations(columns,2):\n",
    "        df['{}+{}'.format(c[0], c[1]) ] = df[c[0]] + '_' + df[c[1]]\n",
    "    return df\n",
    "\n",
    "def categorical_interaction_terms_3(df, columns):\n",
    "    for c in combinations(columns,3):\n",
    "        df['{}+{}+{}'.format(c[0], c[1], c[2]) ] = df[c[0]] + '_' + df[c[1]] + '_' + df[c[2]]\n",
    "    return df\n",
    "\n",
    "train_df = categorical_interaction_terms_2(train_df,interact_cats )\n",
    "#train_df = categorical_interaction_terms_3(train_df,interact_cats )\n",
    "\n",
    "test_df = categorical_interaction_terms_2(test_df,interact_cats )\n",
    "#test_df = categorical_interaction_terms_3(test_df,interact_cats )\n",
    "\n",
    "interact_cats_to_keep = [ 'geoNetwork.city+geoNetwork.networkDomain',\n",
    "  'device.operatingSystem+geoNetwork.networkDomain',\n",
    "  'device.operatingSystem+geoNetwork.city', \n",
    "  'channelGrouping+geoNetwork.networkDomain',\n",
    "  'geoNetwork.city+trafficSource.source',\n",
    " 'geoNetwork.networkDomain+trafficSource.source',\n",
    " 'geoNetwork.networkDomain+trafficSource.referralPath',\n",
    " 'geoNetwork.networkDomain+trafficSource.medium',\n",
    " 'geoNetwork.city+trafficSource.medium',\n",
    " 'geoNetwork.city+geoNetwork.country']\n",
    "\n",
    "#Droping cats not used\n",
    "cat_cols = cat_cols + interact_cats_to_keep\n",
    "to_drop = list( set(train_df.columns[38:]) - set(interact_cats_to_keep)  )\n",
    "train_df.drop(to_drop,inplace = True, axis = 1)\n",
    "test_df.drop(to_drop,inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "57416a80a1e7d73fbba8b53755277fbb240332e2"
   },
   "source": [
    "# Label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "497c0ddbcdc5cc7f61819e2843cca6cd6c156712"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Factorize cats\n",
    "for f in (cat_cols + interact_cats_to_keep ):\n",
    "    train_df[f], indexer = pd.factorize(train_df[f])\n",
    "    test_df[f] = indexer.get_indexer(test_df[f])\n",
    "\n",
    "del indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c839665ea31cdf14443b387eb5f52eb0832f768"
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_flat_FE_CAT_LE.pkl')\n",
    "test_df.to_pickle('test_flat_FE_CAT_LE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "495e6d18764ab36a465d0d511337a2a8bf9f55fa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04bd5e681683d0d9de3af19be9d13b1f73b69c24"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
