{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:23:53.279892Z",
     "start_time": "2019-01-04T09:23:51.936947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:23:59.024823Z",
     "start_time": "2019-01-04T09:23:53.963488Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:23:59.032063Z",
     "start_time": "2019-01-04T09:23:59.028148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (25000,) (25000,)\n",
      "Test: (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", x_train.shape, y_train.shape)\n",
    "print(\"Test:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:23:59.809227Z",
     "start_time": "2019-01-04T09:23:59.805067Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:04.661799Z",
     "start_time": "2019-01-04T09:24:04.597264Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = tf.keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:05.223395Z",
     "start_time": "2019-01-04T09:24:05.213095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:07.564130Z",
     "start_time": "2019-01-04T09:24:07.559228Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = list(vocab.keys())\n",
    "values = list(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:08.422773Z",
     "start_time": "2019-01-04T09:24:08.397478Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a key-word mapping\n",
    "reverse_vocab = dict()\n",
    "for i in range(len(vocab)):\n",
    "    reverse_vocab[values[i]] = keys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:13.323877Z",
     "start_time": "2019-01-04T09:24:13.319867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:16.739835Z",
     "start_time": "2019-01-04T09:24:16.735966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# implement method to get back the original text\n",
    "def get_original_text(vector):\n",
    "    text = list()\n",
    "    for v in vector:\n",
    "        text.append(reverse_vocab[v])\n",
    "    print(\" \".join(text))\n",
    "# call\n",
    "get_original_text(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:21.021317Z",
     "start_time": "2019-01-04T09:24:21.018147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch stefan of solid it thought begins br senator machinations budget worthwhile though ok brokedown awaiting for ever better were lugia diverse for budget look kicked any to of making it out bosworth's follows for effects show to show cast this family us scenes more it severe making senator to levant's finds tv tend to of emerged these thing wants but fuher an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\n"
     ]
    }
   ],
   "source": [
    "get_original_text(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:24.234786Z",
     "start_time": "2019-01-04T09:24:24.229739Z"
    }
   },
   "outputs": [],
   "source": [
    "review_lengths = [len(x) for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:24.533888Z",
     "start_time": "2019-01-04T09:24:24.529789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lengths[0], review_lengths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:28.158149Z",
     "start_time": "2019-01-04T09:24:27.343627Z"
    }
   },
   "outputs": [],
   "source": [
    "# since reviews are not of same len, we need to normalize the length using padding\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=256, padding=\"post\", truncating=\"post\")\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=256, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:28.647772Z",
     "start_time": "2019-01-04T09:24:28.643629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:24:31.440496Z",
     "start_time": "2019-01-04T09:24:31.423851Z"
    }
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:26:06.274617Z",
     "start_time": "2019-01-04T09:26:05.974231Z"
    }
   },
   "outputs": [],
   "source": [
    "# add embedding layer\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(vocab) + 1, input_length=256 , output_dim=512))\n",
    "\n",
    "# add a long short term memory layer\n",
    "model.add(tf.keras.layers.LSTM(units=256, recurrent_dropout=0.3, activation=\"relu\"))\n",
    "\n",
    "# add a long short term memory layer\n",
    "model.add(tf.keras.layers.Dense(units=64))\n",
    "\n",
    "# add a dense sigmoid layer\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:26:07.075336Z",
     "start_time": "2019-01-04T09:26:07.070949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:26:08.082072Z",
     "start_time": "2019-01-04T09:26:08.076793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 256, 512)          45355520  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 46,159,554\n",
      "Trainable params: 46,159,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T09:26:12.593907Z",
     "start_time": "2019-01-04T09:26:12.507554Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-04T09:26:16.069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nityansuman/anaconda3/envs/ai_env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 772s 31ms/step - loss: nan - acc: 0.5016 - val_loss: nan - val_acc: 0.5000\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 770s 31ms/step - loss: nan - acc: 0.5000 - val_loss: nan - val_acc: 0.5000\n",
      "Epoch 3/3\n",
      "24960/25000 [============================>.] - ETA: 1s - loss: nan - acc: 0.5000"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=3, verbose=1, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_env]",
   "language": "python",
   "name": "conda-env-ai_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
