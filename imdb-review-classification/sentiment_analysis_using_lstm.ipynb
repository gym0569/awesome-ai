{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object for imdb dataset\n",
    "data = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset as train and test\n",
    "# consider only top 100,000 words for reviews\n",
    "vocabulary_size = 100000\n",
    "(train_review, train_labels), (test_review, test_labels) = data.load_data(num_words=vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n",
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_review), len(train_labels))\n",
    "print(len(test_review), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 189\n"
     ]
    }
   ],
   "source": [
    "# we expect the reviews to be of different length\n",
    "print(len(train_review[0]), len(train_review[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 512\n",
    "train_review = sequence.pad_sequences(train_review, maxlen=max_words)\n",
    "test_review = sequence.pad_sequences(test_review, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 512, 128)          12800000  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 12,891,701\n",
      "Trainable params: 12,891,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocabulary_size, embedding_size, input_length=max_words),\n",
    "    keras.layers.LSTM(100),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=\"adam\", \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nityansuman/anaconda3/envs/tf3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "24000/24000 [==============================] - 333s 14ms/step - loss: 0.6498 - acc: 0.5993 - val_loss: 0.4688 - val_acc: 0.7760\n",
      "Epoch 2/5\n",
      "24000/24000 [==============================] - 326s 14ms/step - loss: 0.4753 - acc: 0.7774 - val_loss: 0.3903 - val_acc: 0.8390\n",
      "Epoch 3/5\n",
      "24000/24000 [==============================] - 321s 13ms/step - loss: 0.3374 - acc: 0.8536 - val_loss: 0.2884 - val_acc: 0.8870\n",
      "Epoch 4/5\n",
      "24000/24000 [==============================] - 326s 14ms/step - loss: 0.1732 - acc: 0.9380 - val_loss: 0.2672 - val_acc: 0.8970\n",
      "Epoch 5/5\n",
      "24000/24000 [==============================] - 332s 14ms/step - loss: 0.0936 - acc: 0.9698 - val_loss: 0.3938 - val_acc: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3822b7b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "cbk = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "]\n",
    "\n",
    "val_review, val_labels = train_review[:1000], train_labels[:1000]\n",
    "train_review, train_labels = train_review[1000:], train_labels[1000:]\n",
    "\n",
    "model.fit(train_review, train_labels,\n",
    "          validation_data=(val_review, val_labels),\n",
    "          batch_size=batch_size,\n",
    "          callbacks=cbk,\n",
    "          epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
